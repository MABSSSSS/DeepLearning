{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Object Detection?\n",
    "\n",
    "Unlike image classification (which labels an image as a whole), object detection identifies what objects are in an image and where they are.\n",
    "\n",
    "Goal: Detect and classify multiple objects in an image.\n",
    "\n",
    "Common Use Cases:\n",
    "\n",
    "Self-driving cars (pedestrian detection)\n",
    "\n",
    "Face recognition\n",
    "\n",
    "Medical imaging (tumor detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selective Search (Region Proposal Method)\n",
    "\n",
    "Selective Search is an algorithm that generates region proposals where objects might exist.\n",
    "\n",
    "It groups similar pixels to form region proposals.\n",
    "\n",
    "Used in RCNN models for object detection.\n",
    "\n",
    "How Selective Search Works\n",
    "\n",
    "Start with small regions (superpixels).\n",
    "\n",
    "Merge similar regions based on color, texture, size, and shape.\n",
    "\n",
    "Generate object proposals (bounding boxes around possible objects).\n",
    "\n",
    "ðŸ”¹ Pros: Works well for small datasets.\n",
    "\n",
    "ðŸ”¹ Cons: Slow; generates many regions (~2000 per image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Selective Search (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Image\n",
    "image = cv2.imread('example.jpg')\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "# Set the image for Selective Search\n",
    "ss.setBaseImage(image)\n",
    "ss.switchToSelectiveSearchFast()  # Fast mode\n",
    "\n",
    "# Get region proposals\n",
    "rects = ss.process()\n",
    "print(f\"Total region proposals: {len(rects)}\")\n",
    "\n",
    "# Draw first 50 proposals\n",
    "for i, (x, y, w, h) in enumerate(rects[:50]):\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCNN (Region-based CNN)\n",
    "\n",
    "RCNN applies a CNN to each region proposal from Selective Search.\n",
    "\n",
    " Steps in RCNN\n",
    "\n",
    "Generate Region Proposals (Selective Search).\n",
    "\n",
    "Extract Features from each region using a CNN (like AlexNet).\n",
    "\n",
    "Classify Objects using an SVM (Support Vector Machine).\n",
    "\n",
    " Pros: Works well for small datasets.\n",
    "\n",
    " Cons: Slow, since it runs CNN on each region (~2000 times per image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast RCNN (Optimized RCNN)\n",
    "\n",
    "To speed up RCNN:\n",
    "\n",
    "Run CNN once per image (not for each region).\n",
    "\n",
    "Extract region features from CNN feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Load Pre-trained Model\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Extract Features for an image\n",
    "features = base_model.predict(image)  \n",
    "print(\"Feature Map Shape:\", features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO (You Only Look Once) - Real-Time Object Detection\n",
    "\n",
    "Unlike RCNN, YOLO does not use region proposals.\n",
    "\n",
    "Instead, YOLO splits an image into a grid and predicts bounding boxes + class probabilities in one pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing YOLO (Using OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO model and COCO classes\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = open(\"coco.names\").read().strip().split(\"\\n\")\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"example.jpg\")\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Prepare image for YOLO\n",
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "\n",
    "# Get output layers\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Forward pass (get detections)\n",
    "outputs = net.forward(output_layers)\n",
    "\n",
    "# Draw detections\n",
    "for output in outputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        \n",
    "        if confidence > 0.5:\n",
    "            # Get bounding box\n",
    "            center_x, center_y, w, h = (detection[:4] * np.array([width, height, width, height])).astype(\"int\")\n",
    "            x, y = int(center_x - w/2), int(center_y - h/2)\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(image, f\"{classes[class_id]}: {confidence:.2f}\", (x, y - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Show Image\n",
    "cv2.imshow(\"YOLO Detection\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of Object Detection Models\n",
    "\n",
    "**Model**\t**Method**\t     **Speed**\t **Accuracy**\t**Best Use Case**\n",
    "\n",
    "**RCNN**\tSelective Search + CNN\tSlow\tHigh\tMedical Imaging\n",
    "\n",
    "**Fast RCNN**\tCNN feature extraction\tMedium\tHigh\tGeneral Object Detection\n",
    "\n",
    "**YOLO**\tSingle-pass detection\tFast\tHigh\tReal-time applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
